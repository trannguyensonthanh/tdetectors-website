import { Brain, Eye, Layers, Zap } from 'lucide-react';
import attentionMapShowcase from '@/assets/attention-map-showcase.png';

export default function ViT() {
  return (
    <div className="py-16">
      <div className="container mx-auto px-4 sm:px-6 lg:px-8">
        {/* Hero */}
        <div className="max-w-4xl mx-auto text-center mb-16 animate-fade-in-up">
          <div className="inline-block mb-4 px-4 py-2 bg-primary/10 border border-primary/20 rounded-full">
            <span className="text-primary text-sm font-medium">
              Feature Extraction
            </span>
          </div>
          <h1 className="text-4xl lg:text-6xl font-heading font-bold text-foreground mb-6">
            Vision <span className="text-primary">Transformer</span>
          </h1>
          <p className="text-xl text-muted-foreground">
            "B·ªô n√£o nh·∫≠n d·∫°ng" - T·∫°o d·∫•u v√¢n tay h√¨nh ·∫£nh duy nh·∫•t cho m·ªói xe
          </p>
        </div>

        {/* Why ViT after YOLO */}
        <div className="mb-20">
          <div className="bg-gradient-primary rounded-2xl p-8 lg:p-12 mb-12">
            <h2 className="text-3xl font-heading font-bold mb-6">
              T·∫°i sao c·∫ßn ViT sau YOLOv12?
            </h2>
            <div className="grid md:grid-cols-2 gap-8 text-white">
              <div>
                <h3 className="text-xl font-semibold mb-3">
                  üéØ YOLO: ƒê·ªãnh v·ªã v√† ph√¢n lo·∫°i
                </h3>
                <p className="text-white/90">
                  YOLOv12 xu·∫•t s·∫Øc trong vi·ªác <strong>t√¨m ra v·ªã tr√≠</strong> v√†{' '}
                  <strong>ph√¢n lo·∫°i lo·∫°i xe</strong>
                  (car, truck, bus...), nh∆∞ng kh√¥ng t·∫°o ra "ch·ªØ k√Ω" duy nh·∫•t cho
                  t·ª´ng c√° th·ªÉ.
                </p>
              </div>
              <div>
                <h3 className="text-xl font-semibold mb-3">
                  üîç ViT: Nh·∫≠n d·∫°ng c√° th·ªÉ
                </h3>
                <p className="text-white/90">
                  ViT h·ªçc c√°c <strong>ƒë·∫∑c tr∆∞ng tinh t·∫ø</strong> (v·∫øt x∆∞·ªõc,
                  logo, chi ti·∫øt body) ƒë·ªÉ ph√¢n bi·ªát hai chi·∫øc xe c√πng lo·∫°i, c√πng
                  m√†u v·ªõi nhau.
                </p>
              </div>
            </div>
          </div>
        </div>

        {/* Self-Attention Mechanism */}
        <div className="mb-20">
          <h2 className="text-3xl lg:text-4xl font-heading font-bold text-foreground mb-8">
            C∆° ch·∫ø Self-Attention
          </h2>
          <div className="grid lg:grid-cols-2 gap-12 items-center mb-12">
            <div>
              <p className="text-lg text-muted-foreground mb-6">
                Self-attention l√† "si√™u nƒÉng l·ª±c" c·ªßa Transformer, cho ph√©p m√¥
                h√¨nh "nh√¨n" to√†n b·ªô ·∫£nh m·ªôt l√∫c v√† t·ª± ƒë·ªông h·ªçc ƒë∆∞·ª£c ph·∫ßn n√†o
                quan tr·ªçng ƒë·ªÉ nh·∫≠n d·∫°ng.
              </p>
              <div className="space-y-4">
                <div className="bg-card rounded-lg p-6 border border-border">
                  <h3 className="font-heading font-bold mb-2 text-primary">
                    Query, Key, Value
                  </h3>
                  <p className="text-sm text-muted-foreground">
                    M·ªói patch c·ªßa ·∫£nh t·∫°o ra 3 vector: Query (h·ªèi), Key (kh√≥a),
                    Value (gi√° tr·ªã). Attention score = similarity gi·ªØa Query v√†
                    Key.
                  </p>
                </div>
                <div className="bg-card rounded-lg p-6 border border-border">
                  <h3 className="font-heading font-bold mb-2 text-primary">
                    Global Context
                  </h3>
                  <p className="text-sm text-muted-foreground">
                    Kh√°c CNN ch·ªâ nh√¨n receptive field nh·ªè, ViT "nh√¨n" to√†n b·ªô
                    ·∫£nh ngay t·ª´ layer ƒë·∫ßu ti√™n, n·∫Øm b·∫Øt context to√†n c·ª•c.
                  </p>
                </div>
              </div>
            </div>
            <div>
              <img
                src={attentionMapShowcase}
                alt="ViT Attention"
                className="rounded-2xl shadow-card h-96 w-full"
              />
              <p className="text-sm text-muted-foreground text-center mt-4">
                Attention map cho th·∫•y m√¥ h√¨nh t·∫≠p trung v√†o ƒë√¢u
              </p>
            </div>
          </div>
        </div>

        {/* Architecture */}
        <div className="mb-20">
          <h2 className="text-3xl lg:text-4xl font-heading font-bold text-foreground mb-12">
            Ki·∫øn tr√∫c Vision Transformer
          </h2>
          <div className="space-y-8">
            {/* Step 1 */}
            <div className="bg-card rounded-lg p-8 border border-border">
              <div className="flex items-start gap-4 mb-6">
                <div className="w-12 h-12 bg-primary/10 rounded-full flex items-center justify-center flex-shrink-0">
                  <Layers className="h-6 w-6 text-primary" />
                </div>
                <div>
                  <h3 className="text-2xl font-heading font-bold text-foreground mb-2">
                    Patch Embedding
                  </h3>
                  <p className="text-primary font-medium">
                    Chia ·∫£nh th√†nh c√°c patch nh·ªè
                  </p>
                </div>
              </div>
              <div className="ml-16 space-y-3">
                <p className="text-muted-foreground">
                  ·∫¢nh xe 224x224 ƒë∆∞·ª£c chia th√†nh 196 patches (14x14), m·ªói patch
                  16x16 pixels
                </p>
                <p className="text-muted-foreground">
                  M·ªói patch ƒë∆∞·ª£c flatten v√† project th√†nh embedding vector 768-D
                </p>
              </div>
            </div>

            {/* Step 2 */}
            <div className="bg-card rounded-lg p-8 border border-border">
              <div className="flex items-start gap-4 mb-6">
                <div className="w-12 h-12 bg-primary/10 rounded-full flex items-center justify-center flex-shrink-0">
                  <Eye className="h-6 w-6 text-primary" />
                </div>
                <div>
                  <h3 className="text-2xl font-heading font-bold text-foreground mb-2">
                    Positional Encoding
                  </h3>
                  <p className="text-primary font-medium">
                    M√£ h√≥a v·ªã tr√≠ kh√¥ng gian
                  </p>
                </div>
              </div>
              <div className="ml-16 space-y-3">
                <p className="text-muted-foreground">
                  Th√™m learnable position embedding ƒë·ªÉ m√¥ h√¨nh bi·∫øt patch n√†o ·ªü
                  ƒë√¢u trong ·∫£nh
                </p>
                <p className="text-muted-foreground">
                  Quan tr·ªçng v√¨ self-attention kh√¥ng c√≥ kh√°i ni·ªám "th·ª© t·ª±" nh∆∞
                  CNN
                </p>
              </div>
            </div>

            {/* Step 3 */}
            <div className="bg-card rounded-lg p-8 border border-border">
              <div className="flex items-start gap-4 mb-6">
                <div className="w-12 h-12 bg-primary/10 rounded-full flex items-center justify-center flex-shrink-0">
                  <Brain className="h-6 w-6 text-primary" />
                </div>
                <div>
                  <h3 className="text-2xl font-heading font-bold text-foreground mb-2">
                    Transformer Encoder
                  </h3>
                  <p className="text-primary font-medium">
                    12 layers c·ªßa Multi-Head Attention
                  </p>
                </div>
              </div>
              <div className="ml-16 space-y-3">
                <p className="text-muted-foreground">
                  M·ªói layer g·ªìm: Multi-Head Self-Attention ‚Üí Layer Norm ‚Üí MLP ‚Üí
                  Layer Norm
                </p>
                <p className="text-muted-foreground">
                  12 heads cho ph√©p m√¥ h√¨nh h·ªçc nhi·ªÅu "g√≥c nh√¨n" kh√°c nhau v·ªÅ
                  ·∫£nh
                </p>
              </div>
            </div>

            {/* Step 4 */}
            <div className="bg-card rounded-lg p-8 border border-border">
              <div className="flex items-start gap-4 mb-6">
                <div className="w-12 h-12 bg-primary/10 rounded-full flex items-center justify-center flex-shrink-0">
                  <Zap className="h-6 w-6 text-primary" />
                </div>
                <div>
                  <h3 className="text-2xl font-heading font-bold text-foreground mb-2">
                    Global Average Pooling
                  </h3>
                  <p className="text-primary font-medium">
                    T·∫°o embedding vector cu·ªëi c√πng
                  </p>
                </div>
              </div>
              <div className="ml-16 space-y-3">
                <p className="text-muted-foreground">
                  Output c·ªßa 196 patch tokens ƒë∆∞·ª£c average pooling th√†nh 1
                  vector 512-D
                </p>
                <p className="text-muted-foreground">
                  ƒê√¢y ch√≠nh l√† "d·∫•u v√¢n tay h√¨nh ·∫£nh" ƒë·∫°i di·ªán cho to√†n b·ªô
                  ph∆∞∆°ng ti·ªán
                </p>
              </div>
            </div>
          </div>
        </div>

        {/* Advantages */}
        <div>
          <h2 className="text-3xl lg:text-4xl font-heading font-bold text-foreground mb-12">
            ∆Øu ƒëi·ªÉm c·ªßa ViT trong Re-ID
          </h2>
          <div className="grid md:grid-cols-2 gap-8">
            {[
              {
                icon: Eye,
                title: 'Robust v·ªõi thay ƒë·ªïi g√≥c quay',
                description:
                  'Self-attention h·ªçc ƒë∆∞·ª£c relation gi·ªØa c√°c parts b·∫•t k·ªÉ perspective, kh√¥ng b·ªã gi·ªõi h·∫°n b·ªüi receptive field c·ªë ƒë·ªãnh nh∆∞ CNN',
              },
              {
                icon: Brain,
                title: 'H·ªçc global dependencies',
                description:
                  'C√≥ th·ªÉ li√™n k·∫øt th√¥ng tin t·ª´ ƒë·∫ßu xe v√† ƒëu√¥i xe trong m·ªôt layer, quan tr·ªçng khi ch·ªâ nh√¨n th·∫•y m·ªôt ph·∫ßn xe',
              },
              {
                icon: Layers,
                title: 'Feature hierarchy t·ª± ƒë·ªông',
                description:
                  'Kh√¥ng c·∫ßn hand-craft features, ViT t·ª± h·ªçc ƒë∆∞·ª£c ƒë·∫∑c tr∆∞ng n√†o quan tr·ªçng qua attention weights',
              },
              {
                icon: Zap,
                title: 'Pre-training hi·ªáu qu·∫£',
                description:
                  'ViT pre-trained tr√™n ImageNet-21K c√≥ th·ªÉ fine-tune nhanh ch√≥ng cho vehicle Re-ID v·ªõi data √≠t h∆°n',
              },
            ].map((item, index) => (
              <div
                key={index}
                className="bg-card rounded-lg p-6 border border-border"
              >
                <item.icon className="h-10 w-10 text-primary mb-4" />
                <h3 className="text-lg font-heading font-bold text-foreground mb-3">
                  {item.title}
                </h3>
                <p className="text-sm text-muted-foreground">
                  {item.description}
                </p>
              </div>
            ))}
          </div>
        </div>
      </div>
    </div>
  );
}
